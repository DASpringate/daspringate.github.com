<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | DataJujitsu]]></title>
  <link href="http://DASpringate.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://DASpringate.github.io/"/>
  <updated>2014-08-04T16:09:55+01:00</updated>
  <id>http://DASpringate.github.io/</id>
  <author>
    <name><![CDATA[David A Springate]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Scraping organism metadata for Treebase repositories from GOLD using Python and R]]></title>
    <link href="http://DASpringate.github.io/blog/2013/04/16/scraping-organism-metadata-for-treebase-repositories-from-gold-using-python-and-r/"/>
    <updated>2013-04-16T12:37:59+01:00</updated>
    <id>http://DASpringate.github.io/blog/2013/04/16/scraping-organism-metadata-for-treebase-repositories-from-gold-using-python-and-r</id>
    <content type="html"><![CDATA[<p>I recently wanted to get hold of habitat/phenotype/sequencing metadata for the individual organisms of  an archived <a href="http://treebase.org/treebase-web/home.html">Treebase</a> project.</p>

<p>The <a href="http://www.genomesonline.org/">GOLD</a> database holds  more than 18000 full genomes.  For many of these it provides pretty good metadata (<a href="http://genomesonline.org/cgi-bin/GOLD/bin/GOLDCards.cgi?goldstamp=Gc00536">GOLDcards</a>) which are indirectly linked  to Treebase via <a href="http://www.ncbi.nlm.nih.gov/taxonomy">NCBI</a> taxa <a href="http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&amp;amp;id=122368">IDs</a>.</p>

<p>Unfortunately GOLD does not seem to have any kind of API for systematic downloads, so I hacked together a very <a href="https://gist.github.com/2929217">quick-and-dirty scraper</a> in Python that reads in taxa from a Treebase repo, follows the links to each species NCBI page and downloads the linked GOLDcard, if it exists.</p>

<p>Here is the code. You will need the external BeautifulSoup and lxml libraries for this to work &ndash; both are fantastic. (The Treebase repo here is from Wu et al. 2009**, just change the url string for a different repo):</p>

<p>Once you have downloaded all of the available files, It would be great to have your metadata in a nice flatfile with one line per taxa, right?  I did this with a little <a href="https://gist.github.com/2929366">R script</a> using the rather wonderful readHTMLtable() function in the XML (install.packages(&lsquo;XML&rsquo;)) package.</p>

<p>The output is a semicolon separated file with taxa in the rows and the different categories of metadata in columns. The metadata is often fairly incomplete, and  there are plenty of omissions, but hopefully it will become more useful as more deposits are made to GOLD.</p>

<p>** Wu D., Hugenholtz P., Mavromatis K., Pukall R., Dalin E., Ivanova N.N., Kunin V., Goodwin L., Wu M., Tindall B.J., Hooper S.D., Pati A., Lykidis A., Spring S., Anderson I.J., D'haeseleer P., Zemla A., Singer M., Lapidus A., Nolan M., Copeland A., Chen F., Cheng J., Lucas S., Kerfeld C., Lang E., Gronow S., Chain P., Bruce D., Rubin E.M., Kyrpides N.C., Klenk H., &amp; Eisen J.A. 2009. A phylogeny-driven genomic encyclopaedia of Bacteria and Archaea. Nature, 462(7276): 1056-1060.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mapping academic collaborations in Evolutionary Biology]]></title>
    <link href="http://DASpringate.github.io/blog/2013/03/31/mapping-academic-collaborations-in-evolutionary-biology/"/>
    <updated>2013-03-31T15:16:44+01:00</updated>
    <id>http://DASpringate.github.io/blog/2013/03/31/mapping-academic-collaborations-in-evolutionary-biology</id>
    <content type="html"><![CDATA[<p><em>This post is a republication of a visualisation I did in 2011 for my (now defunct) datajujitsu.co.uk blog.  It was a naive first attempt at web-scraping from an academic publishers website.  It was done before I was aware of the problems surrounding access to, and text-mining of, online academic content hosted by publishers such as Wiley and Elsevier. Producing such a piece now (in 2013) would certainly be regarded as a political act. The text and visualisations are unchanged from the original</em></p>

<p>Like many people, I was immensely impressed with Paul Butler&rsquo;s <a href="http://paulbutler.org/archives/visualizing-facebook-friends/">global map of facebook friend connections</a>, a spectacular way of visualising, and humanising, a large amount of raw data.
I was further impressed to find out that he did it solely using R. I recently found Flowingdata&rsquo;s <a href="http://flowingdata.com/2011/05/11/how-to-map-connections-with-great-circles/">tutorial</a> on creating the same effect using flight information and got to thinking about what other datasets I could apply it to.
My original plan was to build a scraper to get all of the abstracts from a particular subject from <a href="http://www.ncbi.nlm.nih.gov/pubmed/">Pubmed</a> and visualise the academic collaborations between institutions for all of these abstracts. Unfortunately though, Pubmed only stores the addresses of the institutions of the corresponding author, so I decided to stick with my own subject, evolutionary biology, and get all the abstacts from the journals <a href="http://onlinelibrary.wiley.com/journal/10.1111/(ISSN">Evolution</a>1558-5646) and <a href="http://onlinelibrary.wiley.com/journal/10.1111/(ISSN">Evolutionary Biology</a>1420-9101) since 2009. I could then extract these using a hacked together Python script which would then feed the addresses into the <a href="http://developer.yahoo.com/geo/placefinder/">Yahoo PlaceFinder</a> api to get a data set of coordinates for each cross-institution collaboration in every paper published in the journals for the last two and a half years.
I then fed this data into R, generated great circles for each of the collaborations using the geosphere package and processed it a la FlowingData to get the following global map of academic collaboration in evolutionary biology since 2009:</p>

<p><img src="/images/posts/evolution_social_network.png" alt="Evolution social network 2009-2011" /></p>

<p>You can clearly see the main hubs of collaboration in Europe and the East and West coasts of the USA, with smaller hubs in Japan and South-Eastern Australia. There are further actively collaborating institutions in South America and Africa, but almost all of their collaborations are with North american and European Universities. Looking into the data itself, the median longitude for JEB institutions is firmly in Europe, while the median longitude for Evolution in the USA (This makes sense since Evolution is based in the states while JEB is a European journal, though there is no geographic imperative to publish in either).
Technical info:
I scraped the data from the Wiley website for the two journals using Python and BeautifulSoup. For the R analysis I used the modules maps, geosphere, reshape and gdata.</p>
]]></content>
  </entry>
  
</feed>
