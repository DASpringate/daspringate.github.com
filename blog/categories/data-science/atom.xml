<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: data science | DataJujitsu]]></title>
  <link href="http://DASpringate.github.io/blog/categories/data-science/atom.xml" rel="self"/>
  <link href="http://DASpringate.github.io/"/>
  <updated>2016-09-06T16:23:34+01:00</updated>
  <id>http://DASpringate.github.io/</id>
  <author>
    <name><![CDATA[David A Springate]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What I am Looking for in a New Data Science Hire]]></title>
    <link href="http://DASpringate.github.io/blog/2016/09/03/what-i-am-looking-for-in-a-new-data-science-hire/"/>
    <updated>2016-09-03T21:39:47+01:00</updated>
    <id>http://DASpringate.github.io/blog/2016/09/03/what-i-am-looking-for-in-a-new-data-science-hire</id>
    <content type="html"><![CDATA[<p>This is my first post for a very long time.  At least part of this tardiness has been because I have been getting to grips with my new role as senior data scientist at <a href="http://www.realitymine.com">RealityMine</a>, a company providing cross-media behavioural data products for marketing and media customers. I started in November 2015 and am now in a second round of recruitment. There are any number of articles online about &lsquo;how to get your first job as a data scientist&rsquo; or &lsquo;What skills a data scientist needs&rsquo;, but for me, many of them feel more like a wish list for the perfect data science degree course, rather than advice for getting a new position &ndash; they are too general and, often seem to be  written by people looking for work as a data scientist rather than someone trying to build up a team. For me, data science is far more than being able to run a Spark job on a Hadoop cluster or to implement a machine learning algorithm: It requires critical thinking, the ability to apply the scientific method in unfamiliar settings and creativity in crafting stories and visualisations from the high-quality information refined from large, messy and complex data. Similarly, big data is not a panacea for modern business: in fact it raises many questions that require the combination of statistical and computational skills with domain knowledge and common sense to effectively address.</p>

<p>In this post I hope to give a flavour of the kinds of skills, knowledge and values that I specifically am looking for when I look at CVs and conduct interviews. Clearly different teams will have different requirements and others may well disagree with me on which are the most important facets, but I wanted to give an insight into what someone on the other side of the recruitment fence values in potential new hires.</p>

<h2>I am looking for:</h2>

<h3>Good conceptual knowledge of maths, statistics and machine learning</h3>

<p>I am not necessarily looking for someone who does Gaussian elimination or eigenvalue decomposition by hand for fun, but I would need them to understand the relationships between rows and columns in matrices and be able to relate them to data and models, and to understand what a PCA is doing, what it might tell us and the impacts on further analysis.  I find it useful to ask around these subjects in an interview, partly to assess for a minimum conceptual understanding of statistics but also to assess the ability to communicate complex ideas to people who may not be an expert in the domain. A complete algebraic understanding is far less important than knowing when to apply a logistic or a linear regression and how to interpret the output. I want people who know the difference between classification, regression, clustering, supervised, unsupervised, predictive modelling, dimension reduction etc. and be able to fairly instinctively know when to apply each, even if they are not sure exactly which model might be the best to apply within each of those groups. I am not necessarily particularly interested if you have coded your own gaussian process model from the bare metal up in C: this may well be impressive but I am looking for practical data scientists who are able to apply their knowledge under a wide range of problems, and if they don&rsquo;t know the answer, they at least have a pretty good idea of where to look for it.</p>

<h3>Data processing and visualisation expertise</h3>

<p>This is perhaps the only absolute essential thing I am looking for and is why &lsquo;pure&rsquo; statisticians with experience only in SPSS, Stata or similar are really not likely to make it past an interview.  I need people who are <em>data manipulation cyborgs</em>, for whom  filtering, subsetting, merging and transforming data is second nature and can do it using their preferred tool (be it <code>dplyr</code>, <code>Pandas</code>, <code>SQL</code> or whatever) with <em>flow</em>, without being hindered by those tools.  Think of the difference between a new driver, who has to think consciously about every single decision (signal, gears, brakes, accelerator, mirrors etc.) and yet is still overloaded with information and someone who has been driving for years for whom many of these tasks are handled by muscle memory and the unconscious brain. Data manipulation is not the chore to get through to get to the proper data science &ndash; it <em>is</em> data science. The same is true for visualisation. Exploring the data always comes before understanding it and visualising data is a hugely important part of this. Personally I spent a lot of time getting familiar enough with <code>ggplot2</code> to be able to crank out quality plots on demand but if you have another favourite that you work efficiently with, that is equally fine.  Related to this is report building, my workflow has been drastically improved by learning to generate automated reports using tools like <code>Rmarkdown</code> and <code>Emacs org-mode</code>. If new hires have already spent the time getting to grips with these tools, they can get to grips with the data that much more quickly.</p>

<h3>Scientific method</h3>

<p>This is critical.  Data scientists lack the specialist and deep software development knowledge of engineers but we are constantly testing hypotheses, experimenting and proving ourselves wrong in our quest for meaning in our data. <a href="https://en.wikipedia.org/wiki/Hypothetico-deductive_model">Hypothetico-deductive</a> thinking is the best method humans have devised for discovery and reasoning where the information we have is incomplete, and I think this is the main reason why many say that science PhDs (rather than Statistics, maths or CS graduates) make the best data scientists. This is drilled into us for at least three years until it becomes second nature (Conversely none of the best engineers I have met have done a PhD &ndash; make of that what you will!).</p>

<h3>An interest in programming</h3>

<p>I am looking for the polyglot data scientist, they may be a wizard at using R, but I need them to understand the circumstances under which it is better to use Python or SQL or bash and be open to diving in to use newer tools like Scala/Spark, if they have not already. I need them to not be constrained to the tools they know the best. A blog, twitter feed, StackExchange presence or GitHub account is a good place to show that you have an interest in the broader issues in data science. An interest in programming and computer science more generally is another big plus &ndash; someone who has spent a little time playing with a few other languages is likely to have a better feel for how their main languages perform under certain conditions. Having a grasp of the differences between functional and object orientated programming and their relative merits for data analysis and pipelines would be a definite benefit. Knowing their way around the linux command line, git and other command line tools is pretty much a prerequisite for hitting the ground running in the first few weeks.</p>

<h3>Domain knowledge</h3>

<p>I work in a fairly disruptive company in an area I had relatively little knowledge of before I joined.  Domain knowledge is often most usefully learned on the job, at least initially, but there should be an interest in the industry you are looking to work in. There is little you can do to prepare yourself for the idiosyncrasies of a new company&rsquo;s data warehouse, however an understanding that it is essentially the same models you are using whether it is in ecology, health informatics, market research or ecommerce automatically puts you in good stead to understanding the data science needs of a  business. From then on the main requirement is curiosity and a thirst for knowledge. I&rsquo;d rather have an ex-ecologist who had split the last few years between cranking out models in R and digging in the dirt for beetles  than someone who had spent 10 years in my industry but who struggled with much more than pivot table in Excel and point-and-click models in SPSS.</p>

<h3>Miscellaneous traits</h3>

<ul>
<li>Need to be comfortable with meetings and explaining complex concepts to people with little or no statistical or technical knowledge</li>
<li>Willingness to learn and also to impart knowledge to other departments and areas in the company.  Data science should never exist in a silo: There is much to learn from BI, engineering, architecture and infrastructure and hopefully much to teach them too!</li>
<li>I don&rsquo;t want someone who just wants to put their headphones on and code 8 hours a day.  There will be many opportunities to get stuck into some proper hacking but I also need the ability to collaborate, tell stories with the data and explain why they are using a particular technique to project managers, salespeople and customers alike</li>
</ul>


<h2>In summary</h2>

<p>So it is conceptual knowledge, technical virtuosity, critical scientific thinking, a love of learning, a gift for communication of complex ideas and a collaborative spirit I look for in a new data scientist hire. I don&rsquo;t much like breaking down data scientists into groups like &lsquo;modellers&rsquo;, &lsquo;visualisers&rsquo; &lsquo;data wranglers&rsquo; etc. Of course different people will be relatively stronger in a given area at any given point in their careers, but data science is an ever-changing environment that selects for generalists and to limit yourself to a certain facet of the discipline is to potentially limit your own opportunities.</p>

<p>I&rsquo;d be interested to hear your opinions. And, by the way, <a href="http://www.realitymine.com/about-us/careers/data-scientist/">We are hiring</a>!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Book Review: Haskell Data Analysis Cookbook]]></title>
    <link href="http://DASpringate.github.io/blog/2014/08/04/book-review-haskell-data-analysis-cookbook/"/>
    <updated>2014-08-04T13:45:29+01:00</updated>
    <id>http://DASpringate.github.io/blog/2014/08/04/book-review-haskell-data-analysis-cookbook</id>
    <content type="html"><![CDATA[<p><a href="http://www.packtpub.com/haskell-data-analysis-cookbook/book">Haskell Data Analysis Cookbook by Nishant Shukla</a></p>

<p>[Full disclosure &ndash; I was given a free review copy of the book from the publisher. This review refers to the ebook version]</p>

<p>Data scientists are spoiled for choice with languages for statistics and data analysis these days.  There is the tried and battle-tested but sometimes plodding workhorse &#40;R), the popular general purpose language with a bunch of fairly new tools (Python), the expensive, closed-source old guard (SAS, Matlab, Stata), C++ for lightning fast calculations but slooow development time, a modern day Lisp with great Java interaction (Clojure) and a new Lisp/Python/R hybrid that is looking to steal Matlab&rsquo;s crown for numerical computation (Julia).  This book sees the purely functional, strongly typed language Haskell throw its hat in the data science ring.</p>

<p>This is a great book for data scientists wanting to leverage the power of functional programming in data analysis applications.  There are chapters on data cleaning, text scraping, hashing, tree traversal, social network analysis, basic stats and machine learning algorithms, mapReduce and visualisation.  It is also good for more general purpose beginner and intermediate level Haskell hackers, since it covers a lot of areas that can be essential in day-to-day programming such as reading and writing data from and to a variety of sources (including databases and the web), text processing, parallel programming and dealing with real time data.  Often in books on haskell (as in many books on Lisp) much space is given to show off the cool FP aspects of the language but you are left struggling with doing the practical IO tasks that are no-brainers in more traditional languages.</p>

<p>The book covers a wide range of subjects, but it provides only a primer for most of them to get you started.  In most cases this is enough, but there are a couple of areas I would have liked to have seen greater depth, for example in the statistics section, a more comprehensive introduction to linear modelling and regression would have been more convincing for R and Python users thinking of switching to Haskell.  I would also have liked to have seen a treatment of random number generation and simulation; the purely functional nature of Haskell seems to make it difficult to generate simple random sequences because you need to set the seed for each run in order to maintain referential transparency (i.e. a function in Haskell generally needs to return the same value for the same input every time).</p>

<p>The examples are well chosen, written and explained and there is also a Github page with the source code from all the chapters if you don&rsquo;t want to type out every one from scratch.  Another nice touch is the list of list of data sources and APIs for doing your own analyses with.  I&rsquo;m sure you could find them with a little Googling but it was good to have them all in one place and there were several I was not aware of.</p>

<p>It must be said that this is not an &lsquo;introduction to Haskell&rsquo; book.  There is plenty of assumed knowledge and the syntax is hardly discussed at all.  However, I would highly recommend anyone starting off with Haskell to get this book alongside an introductory book such as the fantastic &ldquo;Learn you a Haskell for Great Good&rdquo; to get to grips with the mind-bending complexity of the pure FP paradigm alongside the practical real-world applications.</p>

<p>The quality of the book aside, after reading the book I am yet to be convinced that Haskell is a great language for data science.  The static typing and functional purity would be good for building large scale data-centric systems requiring rigorous validation but in my experience, most analytics coding involves lots of rapid prototyping, on-the-fly testing and hacking away at the REPL. It is this style of programming that Python, R and Lisp-based languages excel at &ndash; incrementally growing your codebase to deal with swiftly changing data and conditions.  Haskell seems slightly too rigid to be a comfortable fit; having to think too much about types early on slows down early development (although it could well pay off later on) and the strictness of its functional programming can feel pretty unforgiving. Also the ghci interactive environment just doesn&rsquo;t feel as natural as a Lisp or R REPL. Finally, Haskell seems to be missing other important features such as an equivalent to R&rsquo;s data.frame (which is available in Python, Clojure and Julia) and good interoperability with other systems (such as Weka, R and Hadoop).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Book review: Social Media Mining with R]]></title>
    <link href="http://DASpringate.github.io/blog/2014/06/20/review-social-media-mining-with-r/"/>
    <updated>2014-06-20T21:40:37+01:00</updated>
    <id>http://DASpringate.github.io/blog/2014/06/20/review-social-media-mining-with-r</id>
    <content type="html"><![CDATA[<p><a href="http://www.packtpub.com/social-media-mining-with-r/book">Social Media Mining with R by Nathan Danneman and Richard Heimann</a></p>

<p>[Full disclosure &ndash; I was given a free review copy of the book from the publisher. This review refers to the ebook version]</p>

<p>I worry when a book proposes that it will appeal to everyone.  The trouble is that it could well end up appealing to no-one. The introduction to this new book on social media mining in R says that it will be suitable for skilled programmers with little social science background, people who lack any sort of programming background, people wanting an introduction to social data mining and advanced social science researchers. That doesn&rsquo;t leave many people out!</p>

<p>It turns out that this book doesn&rsquo;t really cover much social media mining.  It does cover basic sentiment analysis and text-mining with some references to twitter data but other social media platforms are barely mentioned and there is no discussion of any of the other social media APIs (e.g. Facebook, Linkedin and Github).  The authors also miss an opportunity to discuss other analysis techniques such as social network analysis and network graphs, which twitter (and other social media) data would be ideal for.</p>

<p>In the first third of the book, much mention is made of big data and how researchers are going to have to prepare for it, but the actual content for dealing with big data (or at least data that would struggle to fit in the RAM of an average laptop) amounts to little more than &ldquo;check that you have enough memory to read in your data and read the manual for the <code>read.table</code> function&rdquo;. R has a reputation for not coping well with large datasets but there are some packages that really assist with this (like <code>fread</code>, <code>data.table</code>, <code>sqldf</code> and <code>dplyr</code>) that could easily have been discussed, along with any number of tips for speeding up I/O using base R functions.</p>

<p>The introductory and background material and theory is interesting and provides a good high level introduction to sentiment analysis, though it still feels somewhat rushed (for example, why completely leave out semi-supervised approaches?  It would have been nice to have at least a page or two describing what they are and why they might be useful) and there is little detail on the assumptions of the different models. The introduction would make a good springboard for deeper research however, and the further reading and bibliography sections are very good.</p>

<p>I like there to be code on nearly every page of a programming book but this one is very light on R code examples. There is a chapter on setting up R and installing packages (This is not going to be anyone&rsquo;s first R book so this chapter feels like a waste, particularly in a book that only clocks in at 120 pages), another covering getting tweets via the <code>twitteR</code> package (but not the streaming API for collecting tweets over a prolonged period of time or any way of storing tweets in a database) and then nothing until two thirds of the way through where there are three short case studies of different methods of sentiment analysis.  It also seems strange to separate out the theory in the earlier chapters and the practical applications later on.</p>

<p>The case studies are mostly decent, covering lexicon-based, naive Bayes and the authors' own unsupervised <em>Item Response Theory</em> sentiment analysis methods.  It seems strange to me in a book on social media mining that the first example doesn&rsquo;t even use social media data, but US government reports which even the authors admit bears little resemblance to twitter data. Some of the code is poorly explained (or not explained at all), idiosyncratic (there may be reasons for using <code>scan</code> to read in a text file, but what are they?) and makes use of out of date packages (Hadley Wickham shipped <code>reshape2</code> back in 2012, why still use <code>reshape</code>?).  The authors miss several opportunities to flesh out the book: One minute they say how important data cleaning is and how useful regular expressions are and then they just point you in the direction of a website teaching regular expressions.  The same is true for the plotting package ggplot2 (Is Wilkinson&rsquo;s <em>The Grammar of Graphics</em> really an appropriate introductory text for this package?) and the <code>rWeka</code> machine learning package.  A lot of the information is good (in particular the description of the <code>tm</code> text-mining package functions) but it all feels a little lightweight, like a collection of blog posts.  The case study analyses were interesting, though choosing such obviously polarised subjects as abortion and Obamacare resulted in much neater, cleaner results than would have been found had subjects been used where opinions are less black-and-white.</p>

<p>Sentiment analysis seems to be everywhere at the moment.  It reminds me of word clouds a few years ago:  Everyone starting out in data science was using them but they soon became a little embarrassing as they became more ubiquitous and were even famously described as the &ldquo;<a href="http://www.zeldman.com/daily/0405d.shtml">mullets of the internet</a>&rdquo;. Make of it what you will that word clouds are used several times as an analysis method in this book.</p>

<p>Users who have maybe done a Coursera data science course or two and want to try their hand at some simple analyses to boost their portfolio will probably find this book useful but more serious users are likely to be left disappointed.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[It's not just for stats: Web mining in R]]></title>
    <link href="http://DASpringate.github.io/blog/2014/06/06/web-mining-in-r/"/>
    <updated>2014-06-06T12:23:23+01:00</updated>
    <id>http://DASpringate.github.io/blog/2014/06/06/web-mining-in-r</id>
    <content type="html"><![CDATA[<p>These are the slides from a talk I gave to the <a href="http://www.rmanchester.org">Manchester R user group</a> on the 6th of May, 2014.</p>

<p>I discussed what web mining(or web scraping) is and the advantages of using R to do it.  Then I provided a toolkit of R functions for Web mining before giving two examples of using web mining for practical uses:</p>

<ol>
<li>Downloading multiple files from a website</li>
<li>A mash-up of data from a number of sources to find out the best places to apply for a new job in academia!</li>
</ol>

]]></content>
  </entry>
  
</feed>
